ä¸‹é¢æ˜¯ä¸€ä¸ª**ç”¨ Go å®ç° Kafka æ¶ˆæ¯é˜Ÿåˆ—**ï¼ˆç”Ÿäº§è€… + æ¶ˆè´¹è€…ï¼‰çš„å®Œæ•´ç¤ºä¾‹ä¸è®²è§£ï¼ŒåŒ…æ‹¬ï¼š

* Kafka çš„æ ¸å¿ƒæ¦‚å¿µ
* Go å®¢æˆ·ç«¯åº“æ¨è
* å®é™…ä»£ç ï¼ˆç”Ÿäº§è€…ã€æ¶ˆè´¹è€…ã€æ¶ˆæ¯ç»“æ„ã€ä¼˜é›…é€€å‡ºï¼‰
* åœ¨é¡¹ç›®ä¸­å¦‚ä½•å°è£…

---

## ä¸€ã€Kafka æ ¸å¿ƒæ¦‚å¿µç®€è¿°

| åç§°                 | å«ä¹‰                           |
| ------------------ | ---------------------------- |
| **Topic**          | æ¶ˆæ¯ä¸»é¢˜ï¼ˆç±»ä¼¼äºæ¶ˆæ¯é˜Ÿåˆ—çš„åå­—ï¼‰             |
| **Producer**       | æ¶ˆæ¯ç”Ÿäº§è€…ï¼Œè´Ÿè´£å‘é€æ¶ˆæ¯åˆ°æŒ‡å®š Topic        |
| **Consumer**       | æ¶ˆæ¯æ¶ˆè´¹è€…ï¼Œä» Topic è¯»å–æ¶ˆæ¯           |
| **Partition**      | æ¯ä¸ª Topic åˆ†ä¸ºå¤šä¸ªåˆ†åŒºï¼Œç”¨äºå¹¶è¡Œå’Œé«˜åå     |
| **Offset**         | æ¯æ¡æ¶ˆæ¯åœ¨åˆ†åŒºä¸­çš„é¡ºåºå·ï¼ˆç±»ä¼¼æ¸¸æ ‡ï¼‰           |
| **Consumer Group** | æ¶ˆè´¹ç»„ï¼ŒKafka ä¿è¯ç»„å†…çš„æ¯ä¸ªåˆ†åŒºåªè¢«ä¸€ä¸ªæ¶ˆè´¹è€…æ¶ˆè´¹ |

---

## äºŒã€Go Kafka å®¢æˆ·ç«¯æ¨è

âœ… **ä¸»æµæ¨èåº“ï¼š**

1. [Shopify/sarama](https://github.com/Shopify/sarama)ï¼ˆç»å…¸ç¨³å®šï¼Œåº”ç”¨å¹¿æ³›ï¼‰
2. [segmentio/kafka-go](https://github.com/segmentio/kafka-go)ï¼ˆæ›´ç®€æ´ã€Go é£æ ¼æ›´å¥½ï¼‰

è¿™é‡Œæˆ‘ä»¬é€‰ **`segmentio/kafka-go`** æ¥æ¼”ç¤ºã€‚

---

## ä¸‰ã€å®‰è£…ä¾èµ–

```bash
go get github.com/segmentio/kafka-go
```

---

## å››ã€ç”Ÿäº§è€…ç¤ºä¾‹ï¼ˆProducerï¼‰

```go
package main

import (
	"context"
	"fmt"
	"github.com/segmentio/kafka-go"
	"time"
)

func main() {
	topic := "test_topic"
	broker := "localhost:9092"

	writer := kafka.NewWriter(kafka.WriterConfig{
		Brokers:  []string{broker},
		Topic:    topic,
		Balancer: &kafka.LeastBytes{},
	})

	defer writer.Close()

	for i := 0; i < 10; i++ {
		msg := fmt.Sprintf("Hello Kafka! message #%d", i)
		err := writer.WriteMessages(context.Background(),
			kafka.Message{
				Key:   []byte(fmt.Sprintf("Key-%d", i)),
				Value: []byte(msg),
			},
		)
		if err != nil {
			fmt.Println("å†™å…¥æ¶ˆæ¯å¤±è´¥:", err)
			break
		}
		fmt.Println("å·²å‘é€:", msg)
		time.Sleep(time.Second)
	}
}
```

### ğŸ” è¯´æ˜

* `WriterConfig` é…ç½®ç”Ÿäº§è€…
* `LeastBytes` è´Ÿè½½å‡è¡¡ç­–ç•¥ï¼šå°†æ¶ˆæ¯å‘å¾€æœ€ç©ºé—²çš„åˆ†åŒº
* `writer.WriteMessages` å‘é€ä¸€æ¡æˆ–å¤šæ¡æ¶ˆæ¯

---

## äº”ã€æ¶ˆè´¹è€…ç¤ºä¾‹ï¼ˆConsumerï¼‰

```go
package main

import (
	"context"
	"fmt"
	"github.com/segmentio/kafka-go"
	"time"
)

func main() {
	topic := "test_topic"
	broker := "localhost:9092"
	groupID := "group_1"

	reader := kafka.NewReader(kafka.ReaderConfig{
		Brokers:  []string{broker},
		GroupID:  groupID,
		Topic:    topic,
		MinBytes: 10e3,  // 10KB
		MaxBytes: 10e6,  // 10MB
	})

	defer reader.Close()

	fmt.Println("å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯...")
	for {
		m, err := reader.ReadMessage(context.Background())
		if err != nil {
			fmt.Println("è¯»å–æ¶ˆæ¯å‡ºé”™:", err)
			break
		}
		fmt.Printf("è¯»å–åˆ°æ¶ˆæ¯: topic=%s partition=%d offset=%d key=%s value=%s\n",
			m.Topic, m.Partition, m.Offset, string(m.Key), string(m.Value))
		time.Sleep(500 * time.Millisecond)
	}
}
```

### ğŸ” è¯´æ˜

* `GroupID` æŒ‡å®šæ¶ˆè´¹è€…ç»„
* Kafka è‡ªåŠ¨ç®¡ç† offsetï¼ˆæ–­ç‚¹ç»­è¯»ï¼‰
* æ¯ä¸ªåˆ†åŒºåŒç»„ä¸­åªä¼šè¢«ä¸€ä¸ªæ¶ˆè´¹è€…è¯»å–

---

## å…­ã€ä¼˜é›…é€€å‡ºï¼ˆGraceful Shutdownï¼‰

```go
ctx, cancel := context.WithCancel(context.Background())
go func() {
    c := make(chan os.Signal, 1)
    signal.Notify(c, os.Interrupt)
    <-c
    fmt.Println("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œå‡†å¤‡é€€å‡º...")
    cancel()
}()

for {
    m, err := reader.ReadMessage(ctx)
    if err != nil {
        if errors.Is(err, context.Canceled) {
            fmt.Println("é€€å‡ºæ¶ˆè´¹è€…å¾ªç¯")
            break
        }
        fmt.Println("è¯»å–é”™è¯¯:", err)
        continue
    }
    fmt.Println("æ¶ˆè´¹:", string(m.Value))
}
```

---

## ä¸ƒã€é¡¹ç›®ä¸­å¦‚ä½•å°è£… Kafka æ¨¡å—

æ¨èå°è£…å¦‚ä¸‹ç›®å½•ç»“æ„ï¼š

```
/internal
  /kafka
    producer.go
    consumer.go
```

ç¤ºä¾‹å°è£…ï¼š

```go
// producer.go
package kafka

import (
	"context"
	"github.com/segmentio/kafka-go"
)

type Producer struct {
	writer *kafka.Writer
}

func NewProducer(brokers []string, topic string) *Producer {
	return &Producer{
		writer: kafka.NewWriter(kafka.WriterConfig{
			Brokers:  brokers,
			Topic:    topic,
			Balancer: &kafka.LeastBytes{},
		}),
	}
}

func (p *Producer) Send(ctx context.Context, key, value []byte) error {
	return p.writer.WriteMessages(ctx, kafka.Message{
		Key:   key,
		Value: value,
	})
}

func (p *Producer) Close() error {
	return p.writer.Close()
}
```

ä½¿ç”¨ï¼š

```go
p := kafka.NewProducer([]string{"localhost:9092"}, "test_topic")
defer p.Close()

_ = p.Send(context.Background(), []byte("key1"), []byte("hello world"))
```

---

## å…«ã€åœ¨å®¹å™¨ä¸­ä½¿ç”¨ Kafkaï¼ˆæœ¬åœ°è°ƒè¯•ï¼‰

ä½¿ç”¨ Docker å¯åŠ¨ä¸€ä¸ªå•èŠ‚ç‚¹ Kafkaï¼š

```bash
docker run -d --name kafka -p 9092:9092 \
  -e KAFKA_BROKER_ID=1 \
  -e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \
  -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 \
  -e KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \
  confluentinc/cp-kafka
```

---

## ä¹ã€å¯æ‰©å±•æ–¹å‘

* âœ… æ”¯æŒ JSON æ¶ˆæ¯ç»“æ„ï¼ˆåºåˆ—åŒ–/ååºåˆ—åŒ–ï¼‰
* âœ… å°è£…ä¸­é—´ä»¶ï¼ˆé‡è¯•ã€æ­»ä¿¡é˜Ÿåˆ—ï¼‰
* âœ… Kafka æ¶ˆè´¹è€…ç›‘æ§ï¼ˆlag å»¶è¿Ÿç›‘æ§ï¼‰
* âœ… åˆ†å¸ƒå¼è¿½è¸ªï¼ˆç»“åˆ Jaegerï¼‰

---

å¦‚æœä½ å‘Šè¯‰æˆ‘ä½ çš„ä½¿ç”¨åœºæ™¯ï¼ˆæ¯”å¦‚ï¼šâ€œå»¶è¿Ÿå¤„ç†ä»»åŠ¡â€ã€â€œå®æ—¶æ—¥å¿—æµâ€ã€â€œåå°æŒ‡ä»¤ä¸‹å‘â€ç­‰ï¼‰ï¼Œ
æˆ‘å¯ä»¥å¸®ä½ è¿›ä¸€æ­¥è®¾è®¡ä¸€ä¸ª**Kafka + Go çš„å®Œæ•´ä¸šåŠ¡æ¶æ„æ–¹æ¡ˆ**ï¼ˆå«å¹¶å‘æ¶ˆè´¹ã€é‡è¯•ã€æŒä¹…åŒ–ï¼‰ã€‚

æ˜¯å¦è¦æˆ‘å¸®ä½ åŸºäºä½ çš„ä¸šåŠ¡åœºæ™¯å®šåˆ¶ä¸€ä¸ªï¼Ÿ
